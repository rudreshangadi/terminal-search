#!/home/yash/anaconda3/bin/python
#This is a simple webscraper to scrap summary of any topic from
#https://en.wikipedia.org
#Assumptions :
#1. The search is well-formed i.e. it can be searched directly searched in
#   wikipedia
#   eg. 'harvard university' will work
#2. Chrome is installed
#3. chromedriver is installed


# importing modules
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
import sys
import requests
from bs4 import BeautifulSoup

# handling parameters obtained from terminal
def search():
    input = sys.argv[1:]
    input = ' '.join(input)
    return input

# setting up a headless browser
def options():
    options = Options()
    options.set_headless(headless = True)
    return options

# navigate to page via selenium
def extract_page(search, options):

    # opening site in web browser
    browser = webdriver.Chrome(chrome_options = options())
    browser.get('https://en.wikipedia.org')

    # searching in seach box
    elem = browser.find_element(by = 'name', value = 'search')
    elem.send_keys(search() + Keys.RETURN)

    # getting the url of the new page
    url = browser.current_url

    # closing browser
    browser.close()

    return url

# opens a socket and returns page content
def scraper(addr):

    # opening a socket and ignoring proxies
    session = requests.Session()
    session.trust_env = False
    source = session.get(addr)

    # reading the data in a variable
    html = source.text
    soup = BeautifulSoup(html, 'html.parser')
    return soup

# finds the appropriate section of page
def print_part(scrap):
    # finding the appropriate section and printing
    paras = scrap.find_all('p')
    req_para = paras[0]
    return req_para.text

# main
addr = extract_page(search, options)
scrap = scraper(addr)
print('\nSummary:\n', print_part(scrap))
